{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyP8xbCE+F/S0UBqRsd0qxX+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodr1ggoql17/Procesamiento-Lenguaje-Natural/blob/main/LDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelado de temas LDA"
      ],
      "metadata": {
        "id": "VKySvnKZj5L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Lane Directly Allocation\" es un método de modelado de temas que identifica temas latentes en un conjunto de documentos.\n",
        "* Utiliza la distribución de Dirichlet para determinar la probabilidad de ciertas palabras aparezcan juntas en documentos y, por lo tantom pueden ser consideradas como parte del mismo \"tema\".\n",
        "* A grandes Rasgos, el LDA trata de determinar qué palabras son más probables que aparezcan en los mismos documentos y, basándose en esom decide que documentos tratan sobre qué temas."
      ],
      "metadata": {
        "id": "UVsbyaiCj8Zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aplicaciones\n",
        "* Descubrimiento de temas\n",
        "* Reducción de dimensionalidad\n",
        "* Recomendaciones"
      ],
      "metadata": {
        "id": "mcZVyCYIk35h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es parte del aprendizaje NO supervisado"
      ],
      "metadata": {
        "id": "fnBPNEAelKsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EJEMPLO"
      ],
      "metadata": {
        "id": "2Hi_J4lrmGx5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPpgDKrjjkKH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "import textwrap\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "qk6DuDsYsZBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "T5htaeKIsUrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops_espanol = set(stopwords.words('spanish')) # guardar stopwords en español"
      ],
      "metadata": {
        "id": "JctM86lhsrah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops_espanol"
      ],
      "metadata": {
        "id": "qUJvTfCMsz-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(stops_espanol)"
      ],
      "metadata": {
        "id": "erg9UpvVs2m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops_espanol = stops_espanol.union({\"así\", \"si\", \"hacer\", \"cosas\",\"creo\", \"cómo\", \"solo\", \"aquí\", \"risas\",\n",
        "                                    \"ser\", \"años\", \"gente\",\"vez\", \"historia\", \"ahora\", \"entonces\", \"bien\", \"puede\",\n",
        "                                    \"pueden\", \"bueno\", \"aplauso\", \"aplausos\",\"ee\",\"uu\", \"datos\", \"personas\",\n",
        "                                    \"hace\", \"hoy\", \"cada\", \"podemos\", \"ver\", \"dos\", \"luego\", \"hecho\", \"realmente\",\n",
        "                                    \"tan\",\"decir\", \"saben\", \"ustedes\",\"dijo\", \"voy\", \"quiero\", \"bf\", \"dh\", \"número\",\n",
        "                                    \"des\", \"gran\", \"día\", \"puedo\", \"mismo\", \"tres\", \"hombres\", \"mujeres\", \"hombre\", \"mujer\",\n",
        "                                    \"hacia\", \"sólo\", \"manera\", \"tipo\", \"mejor\", \"tener\", \"alguien\", \"después\",\"gracias\",\n",
        "                                    \"menos\", \"ejemplo\", \"parte\", \"respuesta\", \"forma\", \"todas\", \"muchas\", \"lugar\", \"poder\",\n",
        "                                    \"incluso\", \"sino\", \"idea\", \"nunca\", \"dije\", \"momento\", \"siempre\", \"podría\", \"veces\", \"ahí\",\n",
        "                                    \"sido\", \"allí\", \"dice\", \"va\"})"
      ],
      "metadata": {
        "id": "OzQwybL0s5D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops_espanol = list(stops_espanol)"
      ],
      "metadata": {
        "id": "imVLys4ztEtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stops_espanol"
      ],
      "metadata": {
        "id": "jqs4qhKptVUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/CURSO NLP/data/ted_talks_es.csv')"
      ],
      "metadata": {
        "id": "MQr8dfsFtXU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gt_a7W7QtgK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['transcript'][0]"
      ],
      "metadata": {
        "id": "1Au6ivpqtqaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words=stops_espanol)\n",
        "\n",
        "x = vectorizer.fit_transform(df['transcript'])\n",
        "x"
      ],
      "metadata": {
        "id": "bZdhVsKHuEUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LDA = LatentDirichletAllocation(\n",
        "    n_components = 10, # 10 temas\n",
        "    random_state = 12354,\n",
        ")"
      ],
      "metadata": {
        "id": "yobJRCyjurui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LDA.fit(x)"
      ],
      "metadata": {
        "id": "UByfCNDEvRQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graficar_palabras_top (model, feature_names, n_top_words=10):\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(30, 15), sharex=True)\n",
        "    axes = axes.flatten()\n",
        "    for topic_idx, topic in enumerate(model.components_):\n",
        "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
        "        top_features = [feature_names[i] for i in top_features_ind]\n",
        "        weights = topic[top_features_ind]\n",
        "\n",
        "        ax = axes[topic_idx]\n",
        "        ax.barh(top_features, weights, height=0.7)\n",
        "        ax.set_title(f\"Tema {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
        "        ax.invert_yaxis()\n",
        "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
        "        for i in \"top right left\".split():\n",
        "            ax.spines[i].set_visible(False)\n",
        "        fig.suptitle('LDA', fontsize=40)\n",
        "\n",
        "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bXF1xp4UvgJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palabras = vectorizer.get_feature_names_out()\n",
        "graficar_palabras_top(LDA, palabras)"
      ],
      "metadata": {
        "id": "2LB4ESVFykQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = LDA.transform(x)"
      ],
      "metadata": {
        "id": "DaqW1RegykFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1111)\n",
        "\n",
        "i = np.random.choice(len(df))\n",
        "Z = z[i]\n",
        "topics = np.arange(10) + 1\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.barh(topics, Z)\n",
        "ax.set_yticks(topics)\n",
        "ax.set_title(\"Charla\");\n",
        "print(i)"
      ],
      "metadata": {
        "id": "m-WwGe0g1VZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wrap(x):\n",
        "    return textwrap.fill(x, replace_whitespace=False, fix_sentence_endings=True)\n",
        "\n",
        "print(wrap(df.iloc[i]['transcript']))"
      ],
      "metadata": {
        "id": "MHHRuM6Z2NTh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}